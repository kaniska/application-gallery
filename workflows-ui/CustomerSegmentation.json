{
  "name": "Customer Segmentation",
  "category": "Machine Learning",
  "description": "Customer Segmentaion - RFM",
  "nodes": [
    {
      "id": "1",
      "name": "DatasetStructured",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "74.7461px",
      "y": "35.375px",
      "fields": [
        {
          "name": "dataset",
          "value": "9fb4dea1-daa3-4abc-ad92-0200d56fcead",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": false,
          "display": true
        }
      ]
    },
    {
      "id": "7",
      "name": "FieldSplitter",
      "description": "This node splits the string at specified delimiter",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFieldSplitter",
      "x": "443.457px",
      "y": "40.0977px",
      "fields": [
        {
          "name": "inputCol",
          "value": "date",
          "widget": "variable",
          "title": "Input Column",
          "description": "input column name",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "outputCols",
          "value": "dt,time",
          "widget": "textfield",
          "title": "Column Names",
          "description": "new column names separed by comma','.(eg: col1,co2,col3)",
          "required": false,
          "display": false
        },
        {
          "name": "sep",
          "value": " ",
          "widget": "textfield",
          "title": "Separator",
          "description": "separator to split the input column value(default: space)",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "8",
      "name": "ColumnFilter",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "743.711px",
      "y": "35.3281px",
      "fields": [
        {
          "name": "outputCols",
          "value": "[\"id\",\"customer_id\",\"product_id\",\"amount\",\"dt\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "9",
      "name": "Scala",
      "description": "This node runs any given Scala code. The input dataframe is passed in the variable inDF. The output dataframe is passed back by registering it as a temporary table.",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeScala",
      "x": "778.957px",
      "y": "209.621px",
      "fields": [
        {
          "name": "code",
          "value": "import java.text.SimpleDateFormat\nimport java.util.Date\nimport org.apache.spark.sql.types.{StructType, StructField, LongType, StringType, IntegerType, DoubleType};\nimport org.apache.spark.sql.Row;\n\n\t\nval defaultDateFormatter = new SimpleDateFormat(\"yyyy-MM-dd\")\nval tempRecords = inDF.rdd.map(row => (row.getLong(0), row.getString(1), row.getString(2), row.getDouble(3), row.getString(4)))\nval records = tempRecords.map(v => v match {case (id, customer_id, product_id, amount, dt) => (customer_id,(defaultDateFormatter.parse(dt), amount))})\n\nval rRecords = records.map(v => (v._1, ((new Date).getTime - v._2._1.getTime)/(24 * 60 * 60 * 1000))).reduceByKey((a:Long, b:Long) => Math.min(a,b))\nval fRecords = records.map(v =>(v._1, 1)).reduceByKey((a:Int,b:Int) => a + b)\nval mRecords = records.map(v =>(v._1, v._2._2)).reduceByKey((a:Double, b:Double) => a + b)\n\nval rfmRecords = rRecords.join(fRecords).join(mRecords).map(v => v match { case (customer_id, ((rValue, fValue), mValue)) => Row(customer_id, rValue, fValue, mValue)})\n                                                                          \nval schema = new StructType(Array(StructField(\"customer_id\", StringType, nullable = true),StructField(\"rValue\", LongType, nullable = true), StructField(\"fValue\", IntegerType, nullable = true), StructField(\"mValue\", DoubleType, nullable = true)))\n\nval outDF = sqlContext.createDataFrame(rfmRecords, schema)\noutDF.registerTempTable(\"outDF\")",
          "widget": "textarea_large",
          "title": "Scala",
          "description": "Scala code to be run. Input dataframe is in \"inDF\". Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": false
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": false
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": false
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "11",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "471.961px",
      "y": "210.602px",
      "fields": [
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": false
        },
        {
          "name": "sql",
          "value": "select customer_id, rValue, fValue , mValue,\ncase when rValue <= 35   then 3.0 \n         when rValue  > 35 and rValue <= 112 then 2.0\n         else 1.0\n         end as rScore,\ncase when fValue >= 15 then 3.0\n         when fValue >= 4 and fValue < 15 then 2.0\n         else 1.0\n         end as fScore,\ncase when mValue >= 50000.0 then 3.0\n         when mValue >= 25000.0 and mValue < 50000.0 then 2.0\n         else 1.0\n         end as mScore,\nmValue / fValue  as avg_amount from fire_temp_table",
          "widget": "textarea_medium",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": false
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"rValue\",\"fValue\",\"mValue\",\"rScore\",\"fScore\",\"mScore\",\"avg_amount\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": false
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"LONG\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": false
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "12",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "128.492px",
      "y": "217.137px",
      "fields": [
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": false
        },
        {
          "name": "sql",
          "value": "select customer_id, cast( (rScore + fScore + mScore) as Double) as  rfmScore, avg_amount from fire_temp_table",
          "widget": "textarea_medium",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": false
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"rfmScore\",\"avg_amount\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": false
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": false
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "13",
      "name": "VectorAssembler",
      "description": "Merges multiple columns into a vector column",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "81.9609px",
      "y": "432.59px",
      "fields": [
        {
          "name": "inputCols",
          "value": "[\"rfmScore\",\"avg_amount\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "outputCol",
          "value": "feature",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "15",
      "name": "KMeans",
      "description": "K-means clustering with support for k-means|| initialization proposed by Bahmani et al",
      "type": "ml-estimator",
      "nodeClass": "fire.nodes.ml.NodeKMeans",
      "x": "782.215px",
      "y": "347.883px",
      "fields": [
        {
          "name": "featuresCol",
          "value": "feature",
          "widget": "variable",
          "title": "Features Column",
          "description": "Features column of type vectorUDT for model fitting.",
          "datatypes": [
            "vectorudt"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "k",
          "value": "5",
          "widget": "textfield",
          "title": "K",
          "description": "The number of clusters to create.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "maxIter",
          "value": "10",
          "widget": "textfield",
          "title": "Max Iterations",
          "description": "The maximum number of iterations.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "predictionCol",
          "widget": "textfield",
          "title": "Prediction Column",
          "description": "The prediction column created during model scoring.",
          "required": false,
          "display": false
        },
        {
          "name": "seed",
          "value": "",
          "widget": "textfield",
          "title": "Seed",
          "description": "Random Seed.",
          "datatypes": [
            "long"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "tol",
          "value": "1e-4",
          "widget": "textfield",
          "title": "Tolerence",
          "description": "The convergence tolerance for iterative algorithms.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "initMode",
          "value": "k-means||",
          "widget": "array",
          "title": "initMode",
          "description": "The initialization algorithm mode.",
          "optionsArray": [
            "k-means||",
            "random"
          ],
          "required": false,
          "display": false
        },
        {
          "name": "initSteps",
          "value": "5",
          "widget": "textfield",
          "title": "initSteps",
          "description": "The number of steps for the k-means|| initialization mode. It will be ignored when other initialization modes are chosen.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "16",
      "name": "Predict",
      "type": "ml-predict",
      "nodeClass": "fire.nodes.ml.NodePredict",
      "x": "791.234px",
      "y": "533.875px",
      "fields": []
    },
    {
      "id": "17",
      "name": "Split",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeSplit",
      "x": "458.238px",
      "y": "430.863px",
      "fields": [
        {
          "name": "fraction1",
          "value": ".5",
          "widget": "textfield",
          "title": "Fraction 1",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "18",
      "name": "PrintNRows",
      "description": "Prints the specified number of records in the DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "786.219px",
      "y": "706.883px",
      "fields": [
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": false
        }
      ]
    },
    {
      "id": "19",
      "name": "Documentation",
      "description": "Allows documentation of the workflows",
      "type": "doc",
      "nodeClass": "fire.nodes.doc.NodeDocLarge",
      "x": "226px",
      "y": "624.656px",
      "fields": [
        {
          "name": "comment",
          "value": "<p>Customer Segmentation using RFM(Recency, Frequency and Monetary)analysis:<br/><br/>Instead of reaching out to 100% of your audience, target only specific customer segments that can prove beneficial for your business in future.<br/><br/>Thus, RFM segmentation will help you strengthen your relationship marketing and increase customer loyalty.<br/><br/>What does RFM stand for?<br/>Recency (R) – How many days ago customer made a purchase? Deduct most recent purchase date from today to calculate the recency value. 1 day ago? 14 days ago? 500 days ago?<br/>Frequency (F) – How many times has the customer purchased from our store? For example, if someone placed 10 orders over a period of time, their frequency is 10.<br/>Monetary (M) – How many $$ (or whatever is your currency of calculation) has this customer spent? Simply total up the money from all transactions to get the M value.<br/>Customers with the most recent purchase, more transactions and spending more money are assigned higher values.<br/><br/>Why RFM segmentation is useful?<br/><br/>Using RFM segmentation, you get to know:<br/>Who are your best customers?<br/>Which customers are at the verge of churning?<br/>Who has the potential to be converted in more profitable customers?<br/>Which customers must be retained?<br/><br/><br/>Workflow<br/><br/>Load and understand the data<br/>We begin by loading our data, which is stored in Comma-Separated Value (CSV) format. For that, we use the CSV node from SparkFlows, which creates a Spark DataFrame.<br/><br/>Data description<br/><br/>id : Continues<br/>customer_id : Continues<br/>product_id: Continues<br/>amount: Continues<br/>DateTime: yyyy-MM-dd HH:mm:SS<br/><br/>Feature extraction and assembler:<br/><br/>    1. FieldSplitterNode: Split the date field into date and time.(choose space as separator)<br/>    2. ScalaNode: Now, calculate the three attributes, Recency, Frequency and Monetary value, separately. First, we use the map method to turn each record into a Key-Value tuple where Customer Id is the key and the required piece of information is the value. Then, we use the reduceByKey to compute the actual aggregate. For example, to calculate Recency, we generate a (Customer Id, Days since last order) tuple and then reduce it by key with a min function. Note that in the code “_1” returns the first element of an n-tuple, “_2” the second element etc. For Frequency, we generate a tuple with CustomerId as key and 1 as value. If we then reduce it by summing, we get the count of tuples (orders). Monetary value is now simple to calculate by adding Order Value’s together.<br/>    Merge the three resulting RDDs into one with a chain of join calls.<br/>    3. Using SQL Node, case statement assign normalized score for each attributes.(like rScore, fScore and mScore)<br/>    4. Using SQL Node, combine the score into rfmScore.<br/>    5. FeatureAssembler: Assemble the feature vector of avgAmount and rfmScore.<br/>    6. Model: Using KMeans algorithm with k=5, cluster the dataset.<br/><br/></p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for Documentation",
          "required": false,
          "display": false
        }
      ]
    }
  ],
  "edges": [
    {
      "source": "7",
      "target": "8",
      "id": 3
    },
    {
      "source": "8",
      "target": "9",
      "id": 4
    },
    {
      "source": "9",
      "target": "11",
      "id": 5
    },
    {
      "source": "11",
      "target": "12",
      "id": 6
    },
    {
      "source": "12",
      "target": "13",
      "id": 7
    },
    {
      "source": "15",
      "target": "16",
      "id": 8
    },
    {
      "source": "13",
      "target": "17",
      "id": 9
    },
    {
      "source": "17",
      "target": "15",
      "id": 10
    },
    {
      "source": "17",
      "target": "16",
      "id": 11
    },
    {
      "source": "16",
      "target": "18",
      "id": 12
    },
    {
      "source": "1",
      "target": "7",
      "id": 13
    }
  ]
}