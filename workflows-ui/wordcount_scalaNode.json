{
  "name": "WordCount - ScalaNode",
  "category": "-",
  "description": "-",
  "nodes": [
    {
      "id": "1",
      "name": "DatasetStructured",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "62px",
      "y": "148.641px",
      "fields": [
        {
          "name": "dataset",
          "value": "6be87dab-55ab-4738-9fa6-97d8de4bd5r3",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": false
        }
      ]
    },
    {
      "id": "2",
      "name": "PrintNRows",
      "description": "Prints the specified number of records in the DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "604px",
      "y": "217.641px",
      "fields": [
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "required": false
        }
      ]
    },
    {
      "id": "3",
      "name": "Scala",
      "description": "This node runs any given Scala code. The input dataframe is passed in the variable inDF. The output dataframe is passed back by registering it as a temporary table.",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeScala",
      "x": "419px",
      "y": "268.641px",
      "fields": [
        {
          "name": "code",
          "value": "import org.apache.spark.sql.types.{StructType,StructField,StringType,IntegerType};\nimport org.apache.spark.sql.Row;\n\n\nval inDFMessage = inDF.select(\"message\")\n\nval wordRDD = inDFMessage.rdd.flatMap(row => row.getString(0).split(\" \"))\nval countRDD = wordRDD.map(word =>(word, 1)).reduceByKey{case(x, y) => x + y}\n\n\nval schema = new StructType(Array(StructField(\"word\", StringType, nullable = true),StructField(\"count\", IntegerType, nullable = true)))\n//val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n\nval rowRDD = countRDD.map{case(word, count) => Row(word, count)}\nval outDF = sqlContext.createDataFrame(rowRDD, schema)\n\noutDF.registerTempTable(\"outDF\")\n\n",
          "widget": "textarea_large",
          "title": "Scala",
          "description": "Scala code to be run. Input dataframe is in \"inDF\". Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false
        },
        {
          "name": "columns",
          "value": "word count",
          "widget": "textfield",
          "title": "Output DataFrame Column Names separated by space",
          "description": "Output DataFrame column names",
          "required": false
        },
        {
          "name": "columnTypes",
          "value": "string long",
          "widget": "textfield",
          "title": "Output DataFrames Column Types",
          "description": "Data Type of the Output Columns",
          "required": false
        }
      ]
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "3",
      "id": 1
    },
    {
      "source": "3",
      "target": "2",
      "id": 2
    }
  ]
}